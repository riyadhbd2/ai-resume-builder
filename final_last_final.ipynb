{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWTkeuK/fVzAVuNq8/OyIN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riyadhbd2/ai-resume-builder/blob/main/final_last_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh5IQ7Gvw2bA",
        "outputId": "f51413ef-1e56-4f70-a5dd-7352aca71ab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Faker\n",
            "  Downloading Faker-26.0.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from Faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->Faker) (1.16.0)\n",
            "Installing collected packages: Faker\n",
            "Successfully installed Faker-26.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install Faker"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DF\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from faker import Faker\n",
        "\n",
        "# Set up Faker instance\n",
        "fake = Faker()\n",
        "\n",
        "# Seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Original data\n",
        "original_data = [\n",
        "   {\"self_test\": \"English proficiency test\", \"item_name\": \"Laptop\", \"cgpa\": 3.5},\n",
        "   # Add more data points as needed\n",
        "]\n",
        "\n",
        "# Function to generate synthetic data\n",
        "def generate_synthetic_data(original_data, num_course=1, num_student=500):\n",
        "   synthetic_data = []\n",
        "   uid_dict = {}  # Dictionary to store UID for each Student_ID\n",
        "   for j in range(1, num_student + 1):\n",
        "       # Generate matriculation number outside inner loop for unique student ID\n",
        "       matriculation_number = np.random.randint(100000, 999999)\n",
        "\n",
        "       # Generate synthetic first name in SN1, SN2, SN3 format\n",
        "       first_name = \"SN\" + str(j)\n",
        "\n",
        "       # Generate synthetic last name in LN1, LN2, LN3 format\n",
        "       last_name = \"LN\" + str(j)\n",
        "\n",
        "       # Generate email in the format \"SN1-LN1@tuchemnitz.de\"\n",
        "       email = f\"{last_name}-{first_name}@tuchemnitz.de\"\n",
        "\n",
        "       # Generate synthetic student user ID only once per Student_ID\n",
        "       if j not in uid_dict:\n",
        "           uid_dict[j] = ''.join(np.random.choice(list('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'), size=30))\n",
        "       uid = uid_dict[j]\n",
        "\n",
        "       for i in range(num_course):\n",
        "           # Create a synthetic data point\n",
        "           synthetic_data.append({\n",
        "               \"Student_ID\": j,\n",
        "               \"Matriculation_Number\": matriculation_number,\n",
        "               \"Last_Name\": last_name,\n",
        "               \"First_Name\": first_name,\n",
        "               \"Email\": email,\n",
        "               \"UID\": uid\n",
        "           })\n",
        "   return synthetic_data\n",
        "\n",
        "# Create DataFrame df\n",
        "synthetic_data = generate_synthetic_data(original_data)\n",
        "df = pd.DataFrame(synthetic_data)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxMPTW-oxZPG",
        "outputId": "94542950-4f19-4642-9f02-6c09a79347b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Student_ID  Matriculation_Number Last_Name First_Name  \\\n",
            "0             1                221958       LN1        SN1   \n",
            "1             2                284779       LN2        SN2   \n",
            "2             3                765987       LN3        SN3   \n",
            "3             4                415139       LN4        SN4   \n",
            "4             5                532315       LN5        SN5   \n",
            "..          ...                   ...       ...        ...   \n",
            "495         496                149810     LN496      SN496   \n",
            "496         497                465213     LN497      SN497   \n",
            "497         498                782527     LN498      SN498   \n",
            "498         499                327997     LN499      SN499   \n",
            "499         500                394849     LN500      SN500   \n",
            "\n",
            "                         Email                             UID  \n",
            "0        LN1-SN1@tuchemnitz.de  ZCoQh8uM5swkkx0JNxcv0bxRDLb7uG  \n",
            "1        LN2-SN2@tuchemnitz.de  5v8RyWA6PB7po99U9YR2Z4cKYguiMr  \n",
            "2        LN3-SN3@tuchemnitz.de  y7nX5iz0btBU7gR8hUInqJXNdb9f1P  \n",
            "3        LN4-SN4@tuchemnitz.de  1CrzRHj9JnEVohnw749NupSrU0xzy7  \n",
            "4        LN5-SN5@tuchemnitz.de  7SOCoSaygixaRhxkYqhIIG6ePM5OBg  \n",
            "..                         ...                             ...  \n",
            "495  LN496-SN496@tuchemnitz.de  gzoU3LcLpbEBgDQ59gJCxZMdCRe2C9  \n",
            "496  LN497-SN497@tuchemnitz.de  CzszKADY0Dc65Qg8W4i0OPmo1eCIAA  \n",
            "497  LN498-SN498@tuchemnitz.de  tjmCI81hCEODvulkbXObHcpYdw4Xty  \n",
            "498  LN499-SN499@tuchemnitz.de  rPkCqz34w3ZVtSbxEAb4ndWmJIR12h  \n",
            "499  LN500-SN500@tuchemnitz.de  fE1jRuPjwcFtjCOZYTHKt88hgfkRrY  \n",
            "\n",
            "[500 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DF2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "# Extract the number of unique students from df\n",
        "num_student = df['Student_ID'].nunique()\n",
        "\n",
        "# Constants\n",
        "num_topics = 39\n",
        "num_semesters = 10\n",
        "\n",
        "# Set a seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Initialize the list for df2 data\n",
        "df2_data = []\n",
        "\n",
        "# Dictionary to keep track of student count for each (topic_id, semester_id) pair\n",
        "student_count = defaultdict(set)\n",
        "\n",
        "# Counter to keep track of the number of unique (Student_ID, Topic_Id, Semester_Id) rows\n",
        "total_rows_needed = num_student\n",
        "\n",
        "while len(df2_data) < total_rows_needed:\n",
        "    student_id = np.random.randint(1, num_student + 1)\n",
        "    topic_id = np.random.randint(1, num_topics + 1)\n",
        "    semester_id = np.random.randint(1, num_semesters + 1)\n",
        "\n",
        "    # Check if the student count for this (topic_id, semester_id) pair is less than 4\n",
        "    if len(student_count[(topic_id, semester_id)]) < 4:\n",
        "        if student_id not in student_count[(topic_id, semester_id)]:\n",
        "            df2_data.append({\n",
        "                \"Student_Id\": student_id,\n",
        "                \"Topic_Id\": topic_id,\n",
        "                \"Semester_Id\": semester_id\n",
        "            })\n",
        "            student_count[(topic_id, semester_id)].add(student_id)\n",
        "\n",
        "# Create the DataFrame df2\n",
        "df2 = pd.DataFrame(df2_data)\n",
        "print(df2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKo95AYcxbIL",
        "outputId": "87dc08ed-bde7-49d2-f28e-710de47df135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Student_Id  Topic_Id  Semester_Id\n",
            "0           103        29            8\n",
            "1           189        21            7\n",
            "2           122        19            7\n",
            "3           331        11            8\n",
            "4           373        36            8\n",
            "..          ...       ...          ...\n",
            "495         158         4            2\n",
            "496         446        37            9\n",
            "497         432         1            5\n",
            "498         494        15            9\n",
            "499         399        24            4\n",
            "\n",
            "[500 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DF3\n",
        "topic_names = [\n",
        "    \"Image segmentation based on Convolutional Neural Network\", \"Advanced Driver Assistance Systems ADAS\",\n",
        "    \"Standards for Safeguarding Highly Automated Driving\", \"Depth estimation from monocular camera based on Convolutional Neural Networks\",\n",
        "    \"Car2X Communication Protocol\", \"Technologies for Internet of Things\", \"AUTOSAR Application Development\",\n",
        "    \"AUTOSAR RTE Test\", \"Image Classification based on Convolutional Neural Network\", \"SLAM with Stereo Cameras\",\n",
        "    \"Car2X Communication Virtual Sensors\", \"Automotive Communication Buses\", \"Car2X Communication Concepts Limitations\",\n",
        "    \"Cyber Physical System\", \"Automotive Ethernet\", \"Depth estimation from stereo camera based on Convolutional Neural Networks\",\n",
        "    \"FPGA based Template Matching for Object Detection in High resolution Image Data\", \"Noise Suppression\",\n",
        "    \"Mixed Criticality Scheduling for Real Time Systems\", \"FPGA based Watershed Segmentation for High resolution Image Data\",\n",
        "    \"AUTOSAR Partitioning\", \"Multicore and AUTOSAR\", \"Adaptive Cruise Control Systems\", \"Car2X Communication Protocols\",\n",
        "    \"Image segmentation based on Convolutional Neural Networks\", \"Analysis of Position Estimation Methods of MAVs\",\n",
        "    \"Comparison of Deep Learning Methods for Impact Detection\", \"Speaker Separation by Computational Auditory Scene Analysis using Directional Filter\",\n",
        "    \"Image Classification based on Convolutional Neural Networks\", \"Sound Source Separation\", \"SLAM with Monocular Cameras\",\n",
        "    \"Bluetooth LE BACHELOR ONLY\", \"Universal Serial Bus Host BACHELOR ONLY\", \"Sound Source Localization\",\n",
        "    \"Mobile detection of Smart City Data for automated Cloud System Evaluation\", \"Automated Evaluation of Smart City Data from Cloud System\",\n",
        "    \"Visualization of Smart City Data from automated Cloud System\", \"Applications of Electroencephalography Based Brain Computer Interface in the Automotive Domain\",\n",
        "    \"Object Detection in 3D point clouds using Deep Learning\"\n",
        "]\n",
        "\n",
        "topic_data = {\n",
        "    \"Topic_ID\": np.arange(1, num_topics + 1),\n",
        "    \"Topic_Name\": topic_names\n",
        "}\n",
        "topic = pd.DataFrame(topic_data)\n",
        "print(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAMsD1j8xeph",
        "outputId": "d78d0a2c-58e2-4b92-e5fe-b46067f77671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Topic_ID                                         Topic_Name\n",
            "0          1  Image segmentation based on Convolutional Neur...\n",
            "1          2            Advanced Driver Assistance Systems ADAS\n",
            "2          3  Standards for Safeguarding Highly Automated Dr...\n",
            "3          4  Depth estimation from monocular camera based o...\n",
            "4          5                       Car2X Communication Protocol\n",
            "5          6                Technologies for Internet of Things\n",
            "6          7                    AUTOSAR Application Development\n",
            "7          8                                   AUTOSAR RTE Test\n",
            "8          9  Image Classification based on Convolutional Ne...\n",
            "9         10                           SLAM with Stereo Cameras\n",
            "10        11                Car2X Communication Virtual Sensors\n",
            "11        12                     Automotive Communication Buses\n",
            "12        13           Car2X Communication Concepts Limitations\n",
            "13        14                              Cyber Physical System\n",
            "14        15                                Automotive Ethernet\n",
            "15        16  Depth estimation from stereo camera based on C...\n",
            "16        17  FPGA based Template Matching for Object Detect...\n",
            "17        18                                  Noise Suppression\n",
            "18        19  Mixed Criticality Scheduling for Real Time Sys...\n",
            "19        20  FPGA based Watershed Segmentation for High res...\n",
            "20        21                               AUTOSAR Partitioning\n",
            "21        22                              Multicore and AUTOSAR\n",
            "22        23                    Adaptive Cruise Control Systems\n",
            "23        24                      Car2X Communication Protocols\n",
            "24        25  Image segmentation based on Convolutional Neur...\n",
            "25        26    Analysis of Position Estimation Methods of MAVs\n",
            "26        27  Comparison of Deep Learning Methods for Impact...\n",
            "27        28  Speaker Separation by Computational Auditory S...\n",
            "28        29  Image Classification based on Convolutional Ne...\n",
            "29        30                            Sound Source Separation\n",
            "30        31                        SLAM with Monocular Cameras\n",
            "31        32                         Bluetooth LE BACHELOR ONLY\n",
            "32        33            Universal Serial Bus Host BACHELOR ONLY\n",
            "33        34                          Sound Source Localization\n",
            "34        35  Mobile detection of Smart City Data for automa...\n",
            "35        36  Automated Evaluation of Smart City Data from C...\n",
            "36        37  Visualization of Smart City Data from automate...\n",
            "37        38  Applications of Electroencephalography Based B...\n",
            "38        39  Object Detection in 3D point clouds using Deep...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame df4\n",
        "semester_names = [\"SS_2020\", \"SS_2021\", \"SS_2022\", \"SS_2023\", \"SS_2024\", \"WS_2019\",\n",
        "                  \"WS_2020\", \"WS_2021\", \"WS_2022\", \"WS_2023\"]\n",
        "\n",
        "semester_data = {\n",
        "    \"Semester_ID\": np.arange(1, num_semesters + 1),\n",
        "    \"Semester_Name\": semester_names\n",
        "}\n",
        "semester = pd.DataFrame(semester_data)\n",
        "print(semester)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI4oCLHWxh3S",
        "outputId": "79c13a1e-6269-4db6-b864-6601fae89227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Semester_ID Semester_Name\n",
            "0            1       SS_2020\n",
            "1            2       SS_2021\n",
            "2            3       SS_2022\n",
            "3            4       SS_2023\n",
            "4            5       SS_2024\n",
            "5            6       WS_2019\n",
            "6            7       WS_2020\n",
            "7            8       WS_2021\n",
            "8            9       WS_2022\n",
            "9           10       WS_2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DF5\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "# Constants\n",
        "num_semesters = 10\n",
        "\n",
        "# Test groups\n",
        "test_group1 = ['Topic Recommender', 'ARS_Search_Gr1', 'ARS_Presentation_Gr1', 'ARS_Discussion_Gr1', 'ARS_Report_Gr1', 'Self_Test_Search', 'Self_Test_Presentation', 'Self_Test_Discussion', 'Self_Test_Report']\n",
        "test_group2 = ['Topic Recommender', 'ARS_Search_Gr2', 'ARS_Presentation_Gr2', 'ARS_Discussion_Gr2', 'ARS_Report_Gr2', 'Self_Test_Search', 'Self_Test_Presentation', 'Self_Test_Discussion', 'Self_Test_Report']\n",
        "\n",
        "# Calculate number of unique students\n",
        "num_unique_students = df['Student_ID'].nunique()\n",
        "\n",
        "# Calculate number of students for each semester\n",
        "students_per_semester = num_unique_students // num_semesters\n",
        "\n",
        "# Calculate number of students for each condition\n",
        "num_students_70_percent = int(0.7 * students_per_semester)\n",
        "num_students_20_percent = int(0.2 * students_per_semester)\n",
        "num_students_10_percent = int(0.1 * students_per_semester)\n",
        "\n",
        "# Initialize lists to store row dictionaries\n",
        "rows = []\n",
        "\n",
        "# Track the students assigned to each condition per semester\n",
        "students_per_condition = {semester_id: {'70_percent': [], '20_percent': [], '10_percent': []} for semester_id in range(1, num_semesters + 1)}\n",
        "\n",
        "# Process for each semester\n",
        "for semester_id in range(1, num_semesters + 1):\n",
        "    available_students = df['Student_ID'].unique()\n",
        "\n",
        "    # Select students randomly to meet the 70% condition\n",
        "    students_meeting_70_percent = np.random.choice(available_students, size=num_students_70_percent, replace=False)\n",
        "    students_per_condition[semester_id]['70_percent'] = students_meeting_70_percent.tolist()\n",
        "\n",
        "    # Assign exactly 9 tests from test_group1 or test_group2 to each student meeting the 70% condition\n",
        "    chosen_list_70 = random.choice([test_group1, test_group2])\n",
        "    for student_id in students_meeting_70_percent:\n",
        "        tests_selected = np.random.choice(chosen_list_70, size=9, replace=False)\n",
        "        for test_name in tests_selected:\n",
        "            row_data = {\n",
        "                \"Test_ID\": len(rows) + 1,\n",
        "                \"Test_Name\": test_name,\n",
        "                \"Student_ID\": student_id,\n",
        "                \"Semester_ID\": semester_id,\n",
        "                \"Duration (in seconds)\": np.random.randint(30, 601),\n",
        "                \"Point_Reached\": int(np.random.uniform(1, 10)),  # Initial arbitrary max\n",
        "                \"Max-Point\": 17  # Initial arbitrary max\n",
        "            }\n",
        "            rows.append(row_data)\n",
        "\n",
        "    # Exclude students already selected for the 70% condition\n",
        "    available_students = [sid for sid in available_students if sid not in students_meeting_70_percent]\n",
        "\n",
        "    # Select students randomly to meet the additional 20% condition\n",
        "    students_meeting_20_percent = np.random.choice(available_students, size=num_students_20_percent, replace=False)\n",
        "    students_per_condition[semester_id]['20_percent'] = students_meeting_20_percent.tolist()\n",
        "\n",
        "    # Assign exactly 9 tests to each student meeting the additional 20% condition\n",
        "    chosen_list_20 = random.choice([test_group1, test_group2])\n",
        "    for student_id in students_meeting_20_percent:\n",
        "        tests_selected = np.random.choice(chosen_list_20, size=9, replace=False)\n",
        "\n",
        "        # Repeat 'ST' test types for this student\n",
        "        st_tests = ['Self_Test_Search', 'Self_Test_Presentation', 'Self_Test_Discussion', 'Self_Test_Report']\n",
        "        st_repeats = np.random.randint(2, 4)  # Choose between 2 or 3 repetitions\n",
        "\n",
        "        for _ in range(st_repeats):\n",
        "            for st_test_name in st_tests:\n",
        "                row_data = {\n",
        "                    \"Test_ID\": len(rows) + 1,\n",
        "                    \"Test_Name\": st_test_name,\n",
        "                    \"Student_ID\": student_id,\n",
        "                    \"Semester_ID\": semester_id,\n",
        "                    \"Duration (in seconds)\": np.random.randint(30, 601),\n",
        "                    \"Point_Reached\": int(np.random.uniform(1, 10)),  # Initial arbitrary max\n",
        "                    \"Max-Point\": 17  # Initial arbitrary max\n",
        "                }\n",
        "                rows.append(row_data)\n",
        "\n",
        "        for test_name in tests_selected:\n",
        "            row_data = {\n",
        "                \"Test_ID\": len(rows) + 1,\n",
        "                \"Test_Name\": test_name,\n",
        "                \"Student_ID\": student_id,\n",
        "                \"Semester_ID\": semester_id,\n",
        "                \"Duration (in seconds)\": np.random.randint(30, 601),\n",
        "                \"Point_Reached\": int(np.random.uniform(1, 10)),  # Initial arbitrary max\n",
        "                \"Max-Point\": 17  # Initial arbitrary max\n",
        "            }\n",
        "            rows.append(row_data)\n",
        "\n",
        "    # Exclude students already selected for the 70% and 20% conditions\n",
        "    available_students = [sid for sid in available_students if sid not in students_meeting_20_percent]\n",
        "\n",
        "    # Select students randomly to exclude from any tests (10% condition)\n",
        "    students_excluded = np.random.choice(available_students, size=num_students_10_percent, replace=False)\n",
        "    students_per_condition[semester_id]['10_percent'] = students_excluded.tolist()\n",
        "\n",
        "# Create DataFrame\n",
        "df5 = pd.DataFrame(rows)\n",
        "df5 = df5[~df5['Student_ID'].isin([sid for sem in students_per_condition.values() for sid in sem['10_percent']])]\n",
        "\n",
        "# Calculate Tries based on Test_Name repetition for each Student_ID\n",
        "df5['Tries'] = df5.groupby(['Student_ID', 'Test_Name']).cumcount() + 1\n",
        "\n",
        "# Adjust Tries to 2 or 3 for repeated tests\n",
        "df5.loc[df5['Tries'] > 3, 'Tries'] = 3\n",
        "\n",
        "# Add Test_Type column based on specified logic\n",
        "test_type = []\n",
        "for name in df5['Test_Name']:\n",
        "    if name == 'Topic Recommender':\n",
        "        test_type.append('TR')\n",
        "    elif name in ['Self_Test_Search', 'Self_Test_Presentation', 'Self_Test_Discussion', 'Self_Test_Report']:\n",
        "        test_type.append('ST')\n",
        "    else:\n",
        "        test_type.append('ARS')\n",
        "\n",
        "df5['Test_Type'] = test_type\n",
        "\n",
        "# Function to generate random date based on conditions\n",
        "def generate_date(semester_id):\n",
        "    if semester_id == 1:\n",
        "        year = 2020\n",
        "        month = random.randint(4, 9)  # April to September\n",
        "    elif semester_id == 2:\n",
        "        year = 2021\n",
        "        month = random.randint(4, 9)  # April to September\n",
        "    elif semester_id == 3:\n",
        "        year = 2022\n",
        "        month = random.randint(4, 9)  # April to September\n",
        "    elif semester_id == 4:\n",
        "        year = 2023\n",
        "        month = random.randint(4, 9)  # April to September\n",
        "    elif semester_id == 5:\n",
        "        year = 2024\n",
        "        month = random.randint(4, 9)  # April to September\n",
        "    elif semester_id == 6:\n",
        "        year = 2019\n",
        "        month = random.randint(10, 12) if random.random() < 0.5 else random.randint(1, 3)  # October to March\n",
        "    elif semester_id == 7:\n",
        "        year = 2020\n",
        "        month = random.randint(10, 12) if random.random() < 0.5 else random.randint(1, 3)  # October to March\n",
        "    elif semester_id == 8:\n",
        "        year = 2021\n",
        "        month = random.randint(10, 12) if random.random() < 0.5 else random.randint(1, 3)  # October to March\n",
        "    elif semester_id == 9:\n",
        "        year = 2022\n",
        "        month = random.randint(10, 12) if random.random() < 0.5 else random.randint(1, 3)  # October to March\n",
        "    elif semester_id == 10:\n",
        "        year = 2023\n",
        "        month = random.randint(10, 12) if random.random() < 0.5 else random.randint(1, 3)  # October to March\n",
        "\n",
        "    day = random.randint(1, 28)  # To avoid issues with different month lengths\n",
        "    hour = random.randint(0, 23)\n",
        "    minute = random.randint(0, 59)\n",
        "    second = random.randint(0, 59)\n",
        "\n",
        "    return datetime(year, month, day, hour, minute, second)\n",
        "\n",
        "# Generate Date column\n",
        "df5['Date'] = df5['Semester_ID'].apply(generate_date)\n",
        "\n",
        "# Format Date column to the required format\n",
        "df5['Date'] = df5['Date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "# Define the mappings for Max-Point based on Test_Name\n",
        "max_point_mapping = {\n",
        "    'Topic Recommender': 17,\n",
        "    'ARS_Search_Gr1': 12,\n",
        "    'ARS_Search_Gr2': 12,\n",
        "    'Self_Test_Search': 12,\n",
        "    'ARS_Presentation_Gr1': 18,\n",
        "    'ARS_Presentation_Gr2': 18,\n",
        "    'Self_Test_Presentation': 18,\n",
        "    'ARS_Discussion_Gr1': 4,\n",
        "    'ARS_Discussion_Gr2': 4,\n",
        "    'Self_Test_Discussion': 4,\n",
        "    'ARS_Report_Gr1': 3,\n",
        "    'ARS_Report_Gr2': 3,\n",
        "    'Self_Test_Report': 3\n",
        "}\n",
        "\n",
        "# Apply the Max-Point mapping to the dataframe\n",
        "df5['Max-Point'] = df5['Test_Name'].map(max_point_mapping)\n",
        "\n",
        "# Ensure Point_Reached does not exceed the new Max-Point\n",
        "df5['Point_Reached'] = df5.apply(lambda row: min(row['Point_Reached'], row['Max-Point']), axis=1)\n",
        "\n",
        "# Reorder the columns as specified\n",
        "df5 = df5[['Test_ID', 'Test_Name', 'Test_Type','Student_ID', 'Semester_ID', 'Date',  'Duration (in seconds)', 'Tries', 'Point_Reached', 'Max-Point']]\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df5.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUzLXFezxlcp",
        "outputId": "3224505e-bd20-4975-b4bf-6d3868c86db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Test_ID               Test_Name Test_Type  Student_ID  Semester_ID  \\\n",
            "0         1          ARS_Search_Gr2       ARS         445            1   \n",
            "1         2    Self_Test_Discussion        ST         445            1   \n",
            "2         3      ARS_Discussion_Gr2       ARS         445            1   \n",
            "3         4       Topic Recommender        TR         445            1   \n",
            "4         5        Self_Test_Report        ST         445            1   \n",
            "5         6  Self_Test_Presentation        ST         445            1   \n",
            "6         7          ARS_Report_Gr2       ARS         445            1   \n",
            "7         8        Self_Test_Search        ST         445            1   \n",
            "8         9    ARS_Presentation_Gr2       ARS         445            1   \n",
            "9        10          ARS_Report_Gr2       ARS         474            1   \n",
            "10       11       Topic Recommender        TR         474            1   \n",
            "11       12        Self_Test_Search        ST         474            1   \n",
            "12       13    ARS_Presentation_Gr2       ARS         474            1   \n",
            "13       14        Self_Test_Report        ST         474            1   \n",
            "14       15  Self_Test_Presentation        ST         474            1   \n",
            "15       16          ARS_Search_Gr2       ARS         474            1   \n",
            "16       17    Self_Test_Discussion        ST         474            1   \n",
            "17       18      ARS_Discussion_Gr2       ARS         474            1   \n",
            "18       19          ARS_Search_Gr2       ARS         112            1   \n",
            "19       20  Self_Test_Presentation        ST         112            1   \n",
            "\n",
            "                   Date  Duration (in seconds)  Tries  Point_Reached  \\\n",
            "0   2020-08-10 21:56:44                    235      1              7   \n",
            "1   2020-04-28 17:11:28                    305      1              4   \n",
            "2   2020-06-03 10:55:31                    245      1              4   \n",
            "3   2020-07-04 12:36:42                    155      1              9   \n",
            "4   2020-04-10 17:22:41                    335      1              3   \n",
            "5   2020-06-27 23:48:29                     68      1              5   \n",
            "6   2020-04-10 12:23:31                    524      1              3   \n",
            "7   2020-08-22 00:20:24                    457      1              5   \n",
            "8   2020-06-26 08:14:07                    180      1              1   \n",
            "9   2020-05-25 12:17:17                    158      1              3   \n",
            "10  2020-06-21 12:05:54                    381      1              3   \n",
            "11  2020-06-12 01:08:19                    524      1              2   \n",
            "12  2020-04-25 14:27:14                    222      1              8   \n",
            "13  2020-04-04 16:24:18                    247      1              3   \n",
            "14  2020-05-05 09:24:28                    443      1              5   \n",
            "15  2020-05-23 11:19:15                    174      1              8   \n",
            "16  2020-07-22 09:17:01                    332      1              4   \n",
            "17  2020-09-02 22:23:34                    374      1              4   \n",
            "18  2020-07-11 19:56:43                    249      1              2   \n",
            "19  2020-07-15 13:21:47                    190      1              4   \n",
            "\n",
            "    Max-Point  \n",
            "0          12  \n",
            "1           4  \n",
            "2           4  \n",
            "3          17  \n",
            "4           3  \n",
            "5          18  \n",
            "6           3  \n",
            "7          12  \n",
            "8          18  \n",
            "9           3  \n",
            "10         17  \n",
            "11         12  \n",
            "12         18  \n",
            "13          3  \n",
            "14         18  \n",
            "15         12  \n",
            "16          4  \n",
            "17          4  \n",
            "18         12  \n",
            "19         18  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DF6\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the 17 distinct Task_Name values\n",
        "task_names = [\"AUTOSAR\", \"Functional Safety\", \"Methodology\", \"Development Process\", \"Tools\",\n",
        "              \"Automation\", \"Smart city\", \"System Safety\", \"Artificial Intelligence (AI)\", \"Protocols\",\n",
        "              \"FPGA\", \"Image Processing\", \"Acoustics\", \"Algorithms\", \"Functionality\", \"Conceptualization\",\n",
        "              \"Complex Systems\"]\n",
        "\n",
        "# Define the 17 distinct Task_ID values\n",
        "task_ids = [\"id045f0e5d-c0ce-4832-9357-10a8a9142e18\", \"id4f02b695-711a-4426-b533-381b206b9206\",\n",
        "            \"id654aebe9-2d82-4eca-bb68-123fac8c0804\", \"id9beb064a-60c8-4e1b-b31d-062a3ee9cd28\",\n",
        "            \"idfc18f003-3d6c-4b71-a227-95c815d006ab\", \"id941d1e27-6e3c-48db-a35b-f19519e333ad\",\n",
        "            \"idd619dd22-609c-4029-9e82-f3a5e66a9ba0\", \"id75d54c62-7223-4122-b91c-9109e60e9825\",\n",
        "            \"id46625526-0c4e-4cf9-969d-9669ee360d98\", \"id858a7861-caaf-4a5c-83c4-6f88b8988e0e\",\n",
        "            \"id3dce97ba-3570-41e1-989c-15db21ff69b2\", \"id135bcf77-5c02-41c4-af81-f79c720341e5\",\n",
        "            \"ideea812e4-28f5-44bd-845a-70f769a5c9f3\", \"id97a4119b-0f74-4e7e-a486-0f0fb77b77b1\",\n",
        "            \"id5540cf88-e826-4390-9e0f-779595968c3f\", \"idc467a2d7-f835-4b32-836c-58686a01c636\",\n",
        "            \"id3de5d417-73cf-4f12-88ff-ba9f62a1380f\"]\n",
        "\n",
        "\n",
        "# Step 1: Extract rows where test_name is 'TR'\n",
        "tr_rows = df5[df5['Test_Type'] == 'TR']\n",
        "\n",
        "# Possible point values\n",
        "possible_points = [0, 1, 0.33, 0.67]\n",
        "\n",
        "def generate_random_points(total, count=17):\n",
        "    if total < 1 or total > 15:\n",
        "        raise ValueError(\"Total points must be between 1 and 15.\")\n",
        "\n",
        "    sequences = {\n",
        "        1: [0.33, 0.67] + [0] * 15,\n",
        "        2: [0.33, 0.67, 1] + [0] * 14,\n",
        "        3: [0.33, 0.67, 1, 0.33, 0.67] + [0] * 12,\n",
        "        4: [0.33, 0.67, 1, 0.33, 0.67, 1] + [0] * 11,\n",
        "        5: [0.33, 0.67, 1, 0.33, 0.67, 1, 1] + [0] * 10,\n",
        "        6: [0.33, 0.67, 1, 0.33, 0.67, 1, 1, 0.33, 0.67] + [0] * 8,\n",
        "        7: [0.33, 0.67, 1, 0.33, 0.67, 1, 1, 0.33, 0.67, 1] + [0] * 7,\n",
        "        8: [0.33, 0.67, 1, 0.33, 0.67, 1, 1, 0.33, 0.67, 1, 1] + [0] * 6,\n",
        "        9: [0.33, 0.67, 1, 0.33, 0.67, 1, 1, 0.33, 0.67, 1, 1, 1] + [0] * 5,\n",
        "        10: [0.33, 0.67, 1, 0.33, 0.67, 1, 1, 0.33, 0.67, 1, 1, 0.33,0.67, 1] + [0] * 3,\n",
        "        11: [0.33, 0.67, 1, 0.33, 0.67, 1, 0.33, 0.67, 0.33, 0.67, 1, 1, 0.33,0.67, 1, 0.33, 0.67],\n",
        "        12: [1,0.33, 0.67,0, 1, 0.33, 0.67, 1, 1, 0.33, 0.67, 1, 1, 0.33,0.67, 1,1],\n",
        "        13: [1, 1, 0.33, 0.67, 1, 0.33, 0.67, 1, 1, 1, 0.33,0.67, 1, 0.33, 0.67,1,1],\n",
        "        14: [0, 1, 0.33, 0.67, 1, 1, 1, 1, 1, 0.33,0.67, 1, 1,1,1,1,1],\n",
        "        15: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.33,0.67, 1, 1,1, 1,0]\n",
        "    }\n",
        "\n",
        "    points = sequences[total]\n",
        "    np.random.shuffle(points)\n",
        "\n",
        "    return np.array(points[:count])\n",
        "\n",
        "# Step 2: For each unique student_id, generate 17 rows with random points\n",
        "df6_list = []\n",
        "for idx, row in tr_rows.iterrows():\n",
        "    student_id = row['Student_ID']\n",
        "    test_id = row['Test_ID']\n",
        "    total_points = row['Point_Reached']\n",
        "    random_points = generate_random_points(total_points)\n",
        "\n",
        "    df6_list.append(pd.DataFrame({\n",
        "        # 'test_name': ['TR'] * 17,\n",
        "        'Student_ID': [student_id] * 17,\n",
        "        'Test_ID': test_id,\n",
        "        'Task_Name': task_names,\n",
        "        'Task_ID': task_ids,\n",
        "        'Points_Reached': random_points\n",
        "    }))\n",
        "\n",
        "# Step 3: Combine all the generated DataFrames into a single DataFrame\n",
        "df6 = pd.concat(df6_list, ignore_index=True)\n",
        "\n",
        "# Step 4: Add a serial column\n",
        "if 'index' in df2.columns:\n",
        "    df2 = df2.drop(columns=['index'])\n",
        "df6 = df6.reset_index(drop=True)\n",
        "df6.insert(0, 'serial', range(1, len(df6) + 1))\n",
        "print(df6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUa7-emMxp7T",
        "outputId": "975f2391-ebb6-487d-98db-76a8a89dd9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      serial  Student_ID  Test_ID            Task_Name  \\\n",
            "0          1         445        4              AUTOSAR   \n",
            "1          2         445        4    Functional Safety   \n",
            "2          3         445        4          Methodology   \n",
            "3          4         445        4  Development Process   \n",
            "4          5         445        4                Tools   \n",
            "...      ...         ...      ...                  ...   \n",
            "7067    7068         109     5057            Acoustics   \n",
            "7068    7069         109     5057           Algorithms   \n",
            "7069    7070         109     5057        Functionality   \n",
            "7070    7071         109     5057    Conceptualization   \n",
            "7071    7072         109     5057      Complex Systems   \n",
            "\n",
            "                                     Task_ID  Points_Reached  \n",
            "0     id045f0e5d-c0ce-4832-9357-10a8a9142e18            0.67  \n",
            "1     id4f02b695-711a-4426-b533-381b206b9206            1.00  \n",
            "2     id654aebe9-2d82-4eca-bb68-123fac8c0804            0.33  \n",
            "3     id9beb064a-60c8-4e1b-b31d-062a3ee9cd28            0.00  \n",
            "4     idfc18f003-3d6c-4b71-a227-95c815d006ab            0.67  \n",
            "...                                      ...             ...  \n",
            "7067  ideea812e4-28f5-44bd-845a-70f769a5c9f3            0.00  \n",
            "7068  id97a4119b-0f74-4e7e-a486-0f0fb77b77b1            0.00  \n",
            "7069  id5540cf88-e826-4390-9e0f-779595968c3f            0.00  \n",
            "7070  idc467a2d7-f835-4b32-836c-58686a01c636            0.00  \n",
            "7071  id3de5d417-73cf-4f12-88ff-ba9f62a1380f            0.67  \n",
            "\n",
            "[7072 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df5 is the existing DataFrame as previously created\n",
        "\n",
        "# Step 1: Create df7 with the required columns from df5\n",
        "df7 = df5[['Student_ID', 'Test_ID', 'Test_Name', 'Test_Type']].copy()\n",
        "\n",
        "# Step 2: Rename columns to match the requirements\n",
        "df7 = df7.rename(columns={\n",
        "    'Student_ID': 'df5_student_ID',\n",
        "    'Test_ID': 'df5_test_ID',\n",
        "    'Test_Name': 'df5_test_name',\n",
        "    'Test_Type': 'df5_test_type'\n",
        "})\n",
        "\n",
        "# Step 3: Filter out rows where the Test_Name is 'Topic Recommender'\n",
        "df7 = df7[df7['df5_test_name'] != 'Topic Recommender']\n",
        "\n",
        "# Step 4: Define the repeat conditions\n",
        "repeat_conditions = {\n",
        "    'Presentation': 2,\n",
        "    'Discussion': 4,\n",
        "    'Report': 3,\n",
        "    'Search': 6\n",
        "}\n",
        "\n",
        "# Step 5: Apply the repeat conditions\n",
        "repeated_rows = []\n",
        "\n",
        "# Loop over each row in the DataFrame\n",
        "for _, row in df7.iterrows():\n",
        "    # Default repeat count is 1\n",
        "    repeat_count = 1\n",
        "\n",
        "    # Check for each keyword in the repeat conditions\n",
        "    for key, count in repeat_conditions.items():\n",
        "        if key in row['df5_test_name']:\n",
        "            repeat_count = count\n",
        "            break  # Exit loop once the condition is matched\n",
        "\n",
        "    # Append the row multiple times according to repeat_count\n",
        "    repeated_rows.extend([row] * repeat_count)\n",
        "\n",
        "# Create the new DataFrame df7 with repeated rows\n",
        "df7 = pd.DataFrame(repeated_rows)\n",
        "\n",
        "# Step 6: Reset the index to maintain a clean DataFrame\n",
        "df7 = df7.reset_index(drop=True)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df7)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErBEoSv39nmg",
        "outputId": "cd121da0-7751-4a59-fb93-b93514615aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       df5_student_ID  df5_test_ID   df5_test_name df5_test_type\n",
            "0                 445            1  ARS_Search_Gr2           ARS\n",
            "1                 445            1  ARS_Search_Gr2           ARS\n",
            "2                 445            1  ARS_Search_Gr2           ARS\n",
            "3                 445            1  ARS_Search_Gr2           ARS\n",
            "4                 445            1  ARS_Search_Gr2           ARS\n",
            "...               ...          ...             ...           ...\n",
            "16045             109         5062  ARS_Search_Gr1           ARS\n",
            "16046             109         5062  ARS_Search_Gr1           ARS\n",
            "16047             109         5062  ARS_Search_Gr1           ARS\n",
            "16048             109         5062  ARS_Search_Gr1           ARS\n",
            "16049             109         5062  ARS_Search_Gr1           ARS\n",
            "\n",
            "[16050 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df5 is the existing DataFrame as previously created\n",
        "\n",
        "# Step 1: Create df7 with the required columns from df5\n",
        "df7 = df5[['Student_ID', 'Test_ID', 'Test_Name', 'Test_Type']].copy()\n",
        "\n",
        "# Step 2: Rename columns to match the requirements\n",
        "df7 = df7.rename(columns={\n",
        "    'Student_ID': 'df5_student_ID',\n",
        "    'Test_ID': 'df5_test_ID',\n",
        "    'Test_Name': 'df5_test_name',\n",
        "    'Test_Type': 'df5_test_type'\n",
        "})\n",
        "\n",
        "# Step 3: Filter out rows where the Test_Name is 'Topic Recommender'\n",
        "df7 = df7[df7['df5_test_name'] != 'Topic Recommender']\n",
        "\n",
        "# Step 4: Define the repeat conditions and corresponding Task_Name mappings\n",
        "repeat_conditions = {\n",
        "    'Presentation': {\n",
        "        'repeat_count': 2,\n",
        "        'task_names': [\"Scientific_Presentation_Style1\", \"Scientific_Presentation_Style2\"]\n",
        "    },\n",
        "    'Discussion': {\n",
        "        'repeat_count': 4,\n",
        "        'task_names': [\"Typical_Question1\", \"Typical_Question2\", \"Typical_Question3\", \"Typical_Question4\"]\n",
        "    },\n",
        "    'Report': {\n",
        "        'repeat_count': 3,\n",
        "        'task_names': [\"Direct_Quotation1\", \"Direct_Quotation2\", \"Indirect_Quotation\"]\n",
        "    },\n",
        "    'Search': {\n",
        "        'repeat_count': 6,\n",
        "        'task_names': [\n",
        "            \"Libraries_Publishers\", \"Literature_Quality1\", \"Literature_Quality2\",\n",
        "            \"Literature_Quality3\", \"Literature_Quality4\", \"Overall_Quality_trustworthiness\"\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Step 5: Apply the repeat conditions and assign Task_Name values\n",
        "repeated_rows = []\n",
        "\n",
        "for _, row in df7.iterrows():\n",
        "    # Default values\n",
        "    repeat_count = 1\n",
        "    task_names = [row['df5_test_name']]  # Default to the test name itself if no condition matches\n",
        "\n",
        "    # Check for each keyword in the repeat conditions\n",
        "    for key, condition in repeat_conditions.items():\n",
        "        if key in row['df5_test_name']:\n",
        "            repeat_count = condition['repeat_count']\n",
        "            task_names = condition['task_names']\n",
        "            break  # Exit loop once the condition is matched\n",
        "\n",
        "    # Append each row with its corresponding Task_Name\n",
        "    for i in range(repeat_count):\n",
        "        new_row = row.copy()\n",
        "        new_row['Task_Name'] = task_names[i]\n",
        "        repeated_rows.append(new_row)\n",
        "\n",
        "# Create the new DataFrame df7 with repeated rows and Task_Name\n",
        "df7 = pd.DataFrame(repeated_rows)\n",
        "\n",
        "# Step 6: Reset the index to maintain a clean DataFrame\n",
        "df7 = df7.reset_index(drop=True)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df7.head(50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GldQy-JwDxRX",
        "outputId": "48a2da4f-57b2-4fb0-a22c-da6819227135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    df5_student_ID  df5_test_ID           df5_test_name df5_test_type  \\\n",
            "0              445            1          ARS_Search_Gr2           ARS   \n",
            "1              445            1          ARS_Search_Gr2           ARS   \n",
            "2              445            1          ARS_Search_Gr2           ARS   \n",
            "3              445            1          ARS_Search_Gr2           ARS   \n",
            "4              445            1          ARS_Search_Gr2           ARS   \n",
            "5              445            1          ARS_Search_Gr2           ARS   \n",
            "6              445            2    Self_Test_Discussion            ST   \n",
            "7              445            2    Self_Test_Discussion            ST   \n",
            "8              445            2    Self_Test_Discussion            ST   \n",
            "9              445            2    Self_Test_Discussion            ST   \n",
            "10             445            3      ARS_Discussion_Gr2           ARS   \n",
            "11             445            3      ARS_Discussion_Gr2           ARS   \n",
            "12             445            3      ARS_Discussion_Gr2           ARS   \n",
            "13             445            3      ARS_Discussion_Gr2           ARS   \n",
            "14             445            5        Self_Test_Report            ST   \n",
            "15             445            5        Self_Test_Report            ST   \n",
            "16             445            5        Self_Test_Report            ST   \n",
            "17             445            6  Self_Test_Presentation            ST   \n",
            "18             445            6  Self_Test_Presentation            ST   \n",
            "19             445            7          ARS_Report_Gr2           ARS   \n",
            "20             445            7          ARS_Report_Gr2           ARS   \n",
            "21             445            7          ARS_Report_Gr2           ARS   \n",
            "22             445            8        Self_Test_Search            ST   \n",
            "23             445            8        Self_Test_Search            ST   \n",
            "24             445            8        Self_Test_Search            ST   \n",
            "25             445            8        Self_Test_Search            ST   \n",
            "26             445            8        Self_Test_Search            ST   \n",
            "27             445            8        Self_Test_Search            ST   \n",
            "28             445            9    ARS_Presentation_Gr2           ARS   \n",
            "29             445            9    ARS_Presentation_Gr2           ARS   \n",
            "30             474           10          ARS_Report_Gr2           ARS   \n",
            "31             474           10          ARS_Report_Gr2           ARS   \n",
            "32             474           10          ARS_Report_Gr2           ARS   \n",
            "33             474           12        Self_Test_Search            ST   \n",
            "34             474           12        Self_Test_Search            ST   \n",
            "35             474           12        Self_Test_Search            ST   \n",
            "36             474           12        Self_Test_Search            ST   \n",
            "37             474           12        Self_Test_Search            ST   \n",
            "38             474           12        Self_Test_Search            ST   \n",
            "39             474           13    ARS_Presentation_Gr2           ARS   \n",
            "40             474           13    ARS_Presentation_Gr2           ARS   \n",
            "41             474           14        Self_Test_Report            ST   \n",
            "42             474           14        Self_Test_Report            ST   \n",
            "43             474           14        Self_Test_Report            ST   \n",
            "44             474           15  Self_Test_Presentation            ST   \n",
            "45             474           15  Self_Test_Presentation            ST   \n",
            "46             474           16          ARS_Search_Gr2           ARS   \n",
            "47             474           16          ARS_Search_Gr2           ARS   \n",
            "48             474           16          ARS_Search_Gr2           ARS   \n",
            "49             474           16          ARS_Search_Gr2           ARS   \n",
            "\n",
            "                          Task_Name  \n",
            "0              Libraries_Publishers  \n",
            "1               Literature_Quality1  \n",
            "2               Literature_Quality2  \n",
            "3               Literature_Quality3  \n",
            "4               Literature_Quality4  \n",
            "5   Overall_Quality_trustworthiness  \n",
            "6                 Typical_Question1  \n",
            "7                 Typical_Question2  \n",
            "8                 Typical_Question3  \n",
            "9                 Typical_Question4  \n",
            "10                Typical_Question1  \n",
            "11                Typical_Question2  \n",
            "12                Typical_Question3  \n",
            "13                Typical_Question4  \n",
            "14                Direct_Quotation1  \n",
            "15                Direct_Quotation2  \n",
            "16               Indirect_Quotation  \n",
            "17   Scientific_Presentation_Style1  \n",
            "18   Scientific_Presentation_Style2  \n",
            "19                Direct_Quotation1  \n",
            "20                Direct_Quotation2  \n",
            "21               Indirect_Quotation  \n",
            "22             Libraries_Publishers  \n",
            "23              Literature_Quality1  \n",
            "24              Literature_Quality2  \n",
            "25              Literature_Quality3  \n",
            "26              Literature_Quality4  \n",
            "27  Overall_Quality_trustworthiness  \n",
            "28   Scientific_Presentation_Style1  \n",
            "29   Scientific_Presentation_Style2  \n",
            "30                Direct_Quotation1  \n",
            "31                Direct_Quotation2  \n",
            "32               Indirect_Quotation  \n",
            "33             Libraries_Publishers  \n",
            "34              Literature_Quality1  \n",
            "35              Literature_Quality2  \n",
            "36              Literature_Quality3  \n",
            "37              Literature_Quality4  \n",
            "38  Overall_Quality_trustworthiness  \n",
            "39   Scientific_Presentation_Style1  \n",
            "40   Scientific_Presentation_Style2  \n",
            "41                Direct_Quotation1  \n",
            "42                Direct_Quotation2  \n",
            "43               Indirect_Quotation  \n",
            "44   Scientific_Presentation_Style1  \n",
            "45   Scientific_Presentation_Style2  \n",
            "46             Libraries_Publishers  \n",
            "47              Literature_Quality1  \n",
            "48              Literature_Quality2  \n",
            "49              Literature_Quality3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DF7\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming df5 is the existing DataFrame as previously created\n",
        "\n",
        "# Step 1: Create df7 with the required columns from df5\n",
        "df7 = df5[['Student_ID', 'Test_ID', 'Test_Name', 'Test_Type']].copy()\n",
        "\n",
        "# Step 2: Rename columns to match the requirements\n",
        "df7 = df7.rename(columns={\n",
        "    'Student_ID': 'df5_student_ID',\n",
        "    'Test_ID': 'df5_test_ID',\n",
        "    'Test_Name': 'df5_test_name',\n",
        "    'Test_Type': 'df5_test_type'\n",
        "})\n",
        "\n",
        "# Step 3: Filter out rows where the Test_Name is 'Topic Recommender'\n",
        "df7 = df7[df7['df5_test_name'] != 'Topic Recommender']\n",
        "\n",
        "# Step 4: Define the repeat conditions, Task_Name, and Task_ID mappings\n",
        "repeat_conditions = {\n",
        "    'Presentation': {\n",
        "        'repeat_count': 2,\n",
        "        'task_names': [\"Scientific_Presentation_Style1\", \"Scientific_Presentation_Style2\"],\n",
        "        'task_ids': [\n",
        "            \"idaf224ec3-be2d-45bb-9f3c-acc818407763\",\n",
        "            \"idfce2e221-452f-4828-bd05-266c2d27e3c0\"\n",
        "        ]\n",
        "    },\n",
        "    'Discussion': {\n",
        "        'repeat_count': 4,\n",
        "        'task_names': [\n",
        "            \"Typical_Question1\",\n",
        "            \"Typical_Question2\",\n",
        "            \"Typical_Question3\",\n",
        "            \"Typical_Question4\"\n",
        "        ],\n",
        "        'task_ids': [\n",
        "            \"id072938f8-9d4c-464a-a096-7779cde74fe6\",\n",
        "            \"id6c761817-f2fe-47bd-8499-540aeed1cbcf\",\n",
        "            \"id615426a1-9c8d-487a-9a49-d8636a489b31\",\n",
        "            \"id4ee22677-08a9-4e7d-94d1-a9bf1fed9aaa\"\n",
        "        ]\n",
        "    },\n",
        "    'Report': {\n",
        "        'repeat_count': 3,\n",
        "        'task_names': [\n",
        "            \"Direct_Quotation1\",\n",
        "            \"Direct_Quotation2\",\n",
        "            \"Indirect_Quotation\"\n",
        "        ],\n",
        "        'task_ids': [\n",
        "            \"ide6f51f20-0250-4df5-917b-911cb8a628bf\",\n",
        "            \"id26fe11e5-5525-456d-9e9b-0810e68126df\",\n",
        "            \"idbe59c174-1a15-4682-b335-abff89b5c6db\"\n",
        "        ]\n",
        "    },\n",
        "    'Search': {\n",
        "        'repeat_count': 6,\n",
        "        'task_names': [\n",
        "            \"Libraries_Publishers\",\n",
        "            \"Literature_Quality1\",\n",
        "            \"Literature_Quality2\",\n",
        "            \"Literature_Quality3\",\n",
        "            \"Literature_Quality4\",\n",
        "            \"Overall_Quality_trustworthiness\"\n",
        "        ],\n",
        "        'task_ids': [\n",
        "            \"idb4b827c3-7fa4-4e7c-b8a4-b8697682c5e2\",\n",
        "            \"idf8870479-86b7-423f-b26d-7b0ce10953a0\",\n",
        "            \"id4d2a3973-cd09-4438-9e5e-9cf7018d4856\",\n",
        "            \"idc4302902-36ef-43c1-8461-7fe7003aeae6\",\n",
        "            \"id88dd75cf-1ec0-4d53-bf36-891d0a4ffef8\",\n",
        "            \"idcac92222-7b93-4ddd-ba3f-ad1e102f22a6\"\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Step 5: Apply the repeat conditions and assign Task_Name and Task_ID values\n",
        "repeated_rows = []\n",
        "\n",
        "for _, row in df7.iterrows():\n",
        "    # Default values\n",
        "    repeat_count = 1\n",
        "    task_names = [row['df5_test_name']]  # Default to the test name itself if no condition matches\n",
        "    task_ids = [None]  # Default to None if no condition matches\n",
        "\n",
        "    # Check for each keyword in the repeat conditions\n",
        "    for key, condition in repeat_conditions.items():\n",
        "        if key in row['df5_test_name']:\n",
        "            repeat_count = condition['repeat_count']\n",
        "            task_names = condition['task_names']\n",
        "            task_ids = condition['task_ids']\n",
        "            break  # Exit loop once the condition is matched\n",
        "\n",
        "    # Append each row with its corresponding Task_Name and Task_ID\n",
        "    for i in range(repeat_count):\n",
        "        new_row = row.copy()\n",
        "        new_row['Task_Name'] = task_names[i]\n",
        "        new_row['Task_ID'] = task_ids[i]\n",
        "        repeated_rows.append(new_row)\n",
        "\n",
        "# Create the new DataFrame df7 with repeated rows, Task_Name, and Task_ID\n",
        "df7 = pd.DataFrame(repeated_rows)\n",
        "\n",
        "# Step 6: Reset the index to maintain a clean DataFrame\n",
        "df7 = df7.reset_index(drop=True)\n",
        "\n",
        "# Define the Max_Score mapping for each Task_Name\n",
        "max_score_mapping = {\n",
        "    \"Scientific_Presentation_Style1\": 10,\n",
        "    \"Scientific_Presentation_Style2\": 8,\n",
        "    \"Typical_Question1\": 1,\n",
        "    \"Typical_Question2\": 1,\n",
        "    \"Typical_Question3\": 1,\n",
        "    \"Typical_Question4\": 1,\n",
        "    \"Direct_Quotation1\": 1,\n",
        "    \"Direct_Quotation2\": 1,\n",
        "    \"Indirect_Quotation\": 1,\n",
        "    \"Libraries_Publishers\": 5,\n",
        "    \"Literature_Quality1\": 1,\n",
        "    \"Literature_Quality2\": 1,\n",
        "    \"Literature_Quality3\": 1,\n",
        "    \"Literature_Quality4\": 1,\n",
        "    \"Overall_Quality_trustworthiness\": 3\n",
        "}\n",
        "\n",
        "# Apply the Max_Score mapping to the dataframe\n",
        "df7['Max_Score'] = df7['Task_Name'].map(max_score_mapping)\n",
        "\n",
        "# Function to generate random points\n",
        "def generate_points(max_score):\n",
        "    if max_score == 1:\n",
        "        return np.random.choice([0, 0.5, 1])\n",
        "    else:\n",
        "        return np.random.randint(1, max_score + 1)\n",
        "\n",
        "# Apply function to create 'Points_Reached' column\n",
        "df7['Points_Reached'] = df7['Max_Score'].apply(generate_points)\n",
        "\n",
        "# Create 'Serial' column with sequential numbers from 1 to number of rows\n",
        "df7['Serial'] = range(1, len(df7) + 1)\n",
        "\n",
        "# Reorder columns\n",
        "df7 = df7[['Serial', 'df5_student_ID', 'df5_test_ID', 'df5_test_name', 'df5_test_type', 'Task_Name', 'Task_ID', 'Points_Reached', 'Max_Score']]\n",
        "\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df7.head(50))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19h6u7MhF0Y4",
        "outputId": "563cdee4-690b-4c22-a833-09cda6198a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Serial  df5_student_ID  df5_test_ID           df5_test_name df5_test_type  \\\n",
            "0        1             445            1          ARS_Search_Gr2           ARS   \n",
            "1        2             445            1          ARS_Search_Gr2           ARS   \n",
            "2        3             445            1          ARS_Search_Gr2           ARS   \n",
            "3        4             445            1          ARS_Search_Gr2           ARS   \n",
            "4        5             445            1          ARS_Search_Gr2           ARS   \n",
            "5        6             445            1          ARS_Search_Gr2           ARS   \n",
            "6        7             445            2    Self_Test_Discussion            ST   \n",
            "7        8             445            2    Self_Test_Discussion            ST   \n",
            "8        9             445            2    Self_Test_Discussion            ST   \n",
            "9       10             445            2    Self_Test_Discussion            ST   \n",
            "10      11             445            3      ARS_Discussion_Gr2           ARS   \n",
            "11      12             445            3      ARS_Discussion_Gr2           ARS   \n",
            "12      13             445            3      ARS_Discussion_Gr2           ARS   \n",
            "13      14             445            3      ARS_Discussion_Gr2           ARS   \n",
            "14      15             445            5        Self_Test_Report            ST   \n",
            "15      16             445            5        Self_Test_Report            ST   \n",
            "16      17             445            5        Self_Test_Report            ST   \n",
            "17      18             445            6  Self_Test_Presentation            ST   \n",
            "18      19             445            6  Self_Test_Presentation            ST   \n",
            "19      20             445            7          ARS_Report_Gr2           ARS   \n",
            "20      21             445            7          ARS_Report_Gr2           ARS   \n",
            "21      22             445            7          ARS_Report_Gr2           ARS   \n",
            "22      23             445            8        Self_Test_Search            ST   \n",
            "23      24             445            8        Self_Test_Search            ST   \n",
            "24      25             445            8        Self_Test_Search            ST   \n",
            "25      26             445            8        Self_Test_Search            ST   \n",
            "26      27             445            8        Self_Test_Search            ST   \n",
            "27      28             445            8        Self_Test_Search            ST   \n",
            "28      29             445            9    ARS_Presentation_Gr2           ARS   \n",
            "29      30             445            9    ARS_Presentation_Gr2           ARS   \n",
            "30      31             474           10          ARS_Report_Gr2           ARS   \n",
            "31      32             474           10          ARS_Report_Gr2           ARS   \n",
            "32      33             474           10          ARS_Report_Gr2           ARS   \n",
            "33      34             474           12        Self_Test_Search            ST   \n",
            "34      35             474           12        Self_Test_Search            ST   \n",
            "35      36             474           12        Self_Test_Search            ST   \n",
            "36      37             474           12        Self_Test_Search            ST   \n",
            "37      38             474           12        Self_Test_Search            ST   \n",
            "38      39             474           12        Self_Test_Search            ST   \n",
            "39      40             474           13    ARS_Presentation_Gr2           ARS   \n",
            "40      41             474           13    ARS_Presentation_Gr2           ARS   \n",
            "41      42             474           14        Self_Test_Report            ST   \n",
            "42      43             474           14        Self_Test_Report            ST   \n",
            "43      44             474           14        Self_Test_Report            ST   \n",
            "44      45             474           15  Self_Test_Presentation            ST   \n",
            "45      46             474           15  Self_Test_Presentation            ST   \n",
            "46      47             474           16          ARS_Search_Gr2           ARS   \n",
            "47      48             474           16          ARS_Search_Gr2           ARS   \n",
            "48      49             474           16          ARS_Search_Gr2           ARS   \n",
            "49      50             474           16          ARS_Search_Gr2           ARS   \n",
            "\n",
            "                          Task_Name                                 Task_ID  \\\n",
            "0              Libraries_Publishers  idb4b827c3-7fa4-4e7c-b8a4-b8697682c5e2   \n",
            "1               Literature_Quality1  idf8870479-86b7-423f-b26d-7b0ce10953a0   \n",
            "2               Literature_Quality2  id4d2a3973-cd09-4438-9e5e-9cf7018d4856   \n",
            "3               Literature_Quality3  idc4302902-36ef-43c1-8461-7fe7003aeae6   \n",
            "4               Literature_Quality4  id88dd75cf-1ec0-4d53-bf36-891d0a4ffef8   \n",
            "5   Overall_Quality_trustworthiness  idcac92222-7b93-4ddd-ba3f-ad1e102f22a6   \n",
            "6                 Typical_Question1  id072938f8-9d4c-464a-a096-7779cde74fe6   \n",
            "7                 Typical_Question2  id6c761817-f2fe-47bd-8499-540aeed1cbcf   \n",
            "8                 Typical_Question3  id615426a1-9c8d-487a-9a49-d8636a489b31   \n",
            "9                 Typical_Question4  id4ee22677-08a9-4e7d-94d1-a9bf1fed9aaa   \n",
            "10                Typical_Question1  id072938f8-9d4c-464a-a096-7779cde74fe6   \n",
            "11                Typical_Question2  id6c761817-f2fe-47bd-8499-540aeed1cbcf   \n",
            "12                Typical_Question3  id615426a1-9c8d-487a-9a49-d8636a489b31   \n",
            "13                Typical_Question4  id4ee22677-08a9-4e7d-94d1-a9bf1fed9aaa   \n",
            "14                Direct_Quotation1  ide6f51f20-0250-4df5-917b-911cb8a628bf   \n",
            "15                Direct_Quotation2  id26fe11e5-5525-456d-9e9b-0810e68126df   \n",
            "16               Indirect_Quotation  idbe59c174-1a15-4682-b335-abff89b5c6db   \n",
            "17   Scientific_Presentation_Style1  idaf224ec3-be2d-45bb-9f3c-acc818407763   \n",
            "18   Scientific_Presentation_Style2  idfce2e221-452f-4828-bd05-266c2d27e3c0   \n",
            "19                Direct_Quotation1  ide6f51f20-0250-4df5-917b-911cb8a628bf   \n",
            "20                Direct_Quotation2  id26fe11e5-5525-456d-9e9b-0810e68126df   \n",
            "21               Indirect_Quotation  idbe59c174-1a15-4682-b335-abff89b5c6db   \n",
            "22             Libraries_Publishers  idb4b827c3-7fa4-4e7c-b8a4-b8697682c5e2   \n",
            "23              Literature_Quality1  idf8870479-86b7-423f-b26d-7b0ce10953a0   \n",
            "24              Literature_Quality2  id4d2a3973-cd09-4438-9e5e-9cf7018d4856   \n",
            "25              Literature_Quality3  idc4302902-36ef-43c1-8461-7fe7003aeae6   \n",
            "26              Literature_Quality4  id88dd75cf-1ec0-4d53-bf36-891d0a4ffef8   \n",
            "27  Overall_Quality_trustworthiness  idcac92222-7b93-4ddd-ba3f-ad1e102f22a6   \n",
            "28   Scientific_Presentation_Style1  idaf224ec3-be2d-45bb-9f3c-acc818407763   \n",
            "29   Scientific_Presentation_Style2  idfce2e221-452f-4828-bd05-266c2d27e3c0   \n",
            "30                Direct_Quotation1  ide6f51f20-0250-4df5-917b-911cb8a628bf   \n",
            "31                Direct_Quotation2  id26fe11e5-5525-456d-9e9b-0810e68126df   \n",
            "32               Indirect_Quotation  idbe59c174-1a15-4682-b335-abff89b5c6db   \n",
            "33             Libraries_Publishers  idb4b827c3-7fa4-4e7c-b8a4-b8697682c5e2   \n",
            "34              Literature_Quality1  idf8870479-86b7-423f-b26d-7b0ce10953a0   \n",
            "35              Literature_Quality2  id4d2a3973-cd09-4438-9e5e-9cf7018d4856   \n",
            "36              Literature_Quality3  idc4302902-36ef-43c1-8461-7fe7003aeae6   \n",
            "37              Literature_Quality4  id88dd75cf-1ec0-4d53-bf36-891d0a4ffef8   \n",
            "38  Overall_Quality_trustworthiness  idcac92222-7b93-4ddd-ba3f-ad1e102f22a6   \n",
            "39   Scientific_Presentation_Style1  idaf224ec3-be2d-45bb-9f3c-acc818407763   \n",
            "40   Scientific_Presentation_Style2  idfce2e221-452f-4828-bd05-266c2d27e3c0   \n",
            "41                Direct_Quotation1  ide6f51f20-0250-4df5-917b-911cb8a628bf   \n",
            "42                Direct_Quotation2  id26fe11e5-5525-456d-9e9b-0810e68126df   \n",
            "43               Indirect_Quotation  idbe59c174-1a15-4682-b335-abff89b5c6db   \n",
            "44   Scientific_Presentation_Style1  idaf224ec3-be2d-45bb-9f3c-acc818407763   \n",
            "45   Scientific_Presentation_Style2  idfce2e221-452f-4828-bd05-266c2d27e3c0   \n",
            "46             Libraries_Publishers  idb4b827c3-7fa4-4e7c-b8a4-b8697682c5e2   \n",
            "47              Literature_Quality1  idf8870479-86b7-423f-b26d-7b0ce10953a0   \n",
            "48              Literature_Quality2  id4d2a3973-cd09-4438-9e5e-9cf7018d4856   \n",
            "49              Literature_Quality3  idc4302902-36ef-43c1-8461-7fe7003aeae6   \n",
            "\n",
            "    Points_Reached  Max_Score  \n",
            "0              1.0          5  \n",
            "1              1.0          1  \n",
            "2              0.5          1  \n",
            "3              1.0          1  \n",
            "4              0.0          1  \n",
            "5              3.0          3  \n",
            "6              1.0          1  \n",
            "7              0.5          1  \n",
            "8              0.0          1  \n",
            "9              0.0          1  \n",
            "10             0.5          1  \n",
            "11             1.0          1  \n",
            "12             1.0          1  \n",
            "13             0.0          1  \n",
            "14             1.0          1  \n",
            "15             0.5          1  \n",
            "16             0.0          1  \n",
            "17            10.0         10  \n",
            "18             6.0          8  \n",
            "19             0.0          1  \n",
            "20             0.0          1  \n",
            "21             1.0          1  \n",
            "22             3.0          5  \n",
            "23             1.0          1  \n",
            "24             0.5          1  \n",
            "25             0.5          1  \n",
            "26             1.0          1  \n",
            "27             1.0          3  \n",
            "28             6.0         10  \n",
            "29             2.0          8  \n",
            "30             1.0          1  \n",
            "31             0.0          1  \n",
            "32             0.5          1  \n",
            "33             1.0          5  \n",
            "34             0.5          1  \n",
            "35             0.0          1  \n",
            "36             0.0          1  \n",
            "37             0.5          1  \n",
            "38             1.0          3  \n",
            "39            10.0         10  \n",
            "40             2.0          8  \n",
            "41             0.0          1  \n",
            "42             0.5          1  \n",
            "43             0.0          1  \n",
            "44            10.0         10  \n",
            "45             1.0          8  \n",
            "46             2.0          5  \n",
            "47             0.5          1  \n",
            "48             1.0          1  \n",
            "49             0.5          1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DF7\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming df5 is the existing DataFrame as previously created\n",
        "\n",
        "# Step 1: Create df7 with the required columns from df5\n",
        "df7 = df5[['Student_ID', 'Test_ID', 'Test_Name', 'Test_Type']].copy()\n",
        "\n",
        "# Step 2: Rename columns to match the requirements\n",
        "df7 = df7.rename(columns={\n",
        "    'Student_ID': 'Student_ID',\n",
        "    'Test_ID': 'Test_ID',\n",
        "    'Test_Name': 'Test_Name',\n",
        "    'Test_Type': 'Test_Type'\n",
        "})\n",
        "\n",
        "# Step 3: Filter out rows where the Test_Name is 'Topic Recommender'\n",
        "df7 = df7[df7['Test_Name'] != 'Topic Recommender']\n",
        "\n",
        "# Step 4: Define the repeat conditions, Task_Name, and Task_ID mappings\n",
        "repeat_conditions = {\n",
        "    'Presentation': {\n",
        "        'repeat_count': 2,\n",
        "        'task_names': [\"Scientific_Presentation_Style1\", \"Scientific_Presentation_Style2\"],\n",
        "        'task_ids': [\n",
        "            \"idaf224ec3-be2d-45bb-9f3c-acc818407763\",\n",
        "            \"idfce2e221-452f-4828-bd05-266c2d27e3c0\"\n",
        "        ]\n",
        "    },\n",
        "    'Discussion': {\n",
        "        'repeat_count': 4,\n",
        "        'task_names': [\n",
        "            \"Typical_Question1\",\n",
        "            \"Typical_Question2\",\n",
        "            \"Typical_Question3\",\n",
        "            \"Typical_Question4\"\n",
        "        ],\n",
        "        'task_ids': [\n",
        "            \"id072938f8-9d4c-464a-a096-7779cde74fe6\",\n",
        "            \"id6c761817-f2fe-47bd-8499-540aeed1cbcf\",\n",
        "            \"id615426a1-9c8d-487a-9a49-d8636a489b31\",\n",
        "            \"id4ee22677-08a9-4e7d-94d1-a9bf1fed9aaa\"\n",
        "        ]\n",
        "    },\n",
        "    'Report': {\n",
        "        'repeat_count': 3,\n",
        "        'task_names': [\n",
        "            \"Direct_Quotation1\",\n",
        "            \"Direct_Quotation2\",\n",
        "            \"Indirect_Quotation\"\n",
        "        ],\n",
        "        'task_ids': [\n",
        "            \"ide6f51f20-0250-4df5-917b-911cb8a628bf\",\n",
        "            \"id26fe11e5-5525-456d-9e9b-0810e68126df\",\n",
        "            \"idbe59c174-1a15-4682-b335-abff89b5c6db\"\n",
        "        ]\n",
        "    },\n",
        "    'Search': {\n",
        "        'repeat_count': 6,\n",
        "        'task_names': [\n",
        "            \"Libraries_Publishers\",\n",
        "            \"Literature_Quality1\",\n",
        "            \"Literature_Quality2\",\n",
        "            \"Literature_Quality3\",\n",
        "            \"Literature_Quality4\",\n",
        "            \"Overall_Quality_trustworthiness\"\n",
        "        ],\n",
        "        'task_ids': [\n",
        "            \"idb4b827c3-7fa4-4e7c-b8a4-b8697682c5e2\",\n",
        "            \"idf8870479-86b7-423f-b26d-7b0ce10953a0\",\n",
        "            \"id4d2a3973-cd09-4438-9e5e-9cf7018d4856\",\n",
        "            \"idc4302902-36ef-43c1-8461-7fe7003aeae6\",\n",
        "            \"id88dd75cf-1ec0-4d53-bf36-891d0a4ffef8\",\n",
        "            \"idcac92222-7b93-4ddd-ba3f-ad1e102f22a6\"\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Step 5: Apply the repeat conditions and assign Task_Name and Task_ID values\n",
        "repeated_rows = []\n",
        "\n",
        "for _, row in df7.iterrows():\n",
        "    # Default values\n",
        "    repeat_count = 1\n",
        "    task_names = [row['Test_Name']]  # Default to the test name itself if no condition matches\n",
        "    task_ids = [None]  # Default to None if no condition matches\n",
        "\n",
        "    # Check for each keyword in the repeat conditions\n",
        "    for key, condition in repeat_conditions.items():\n",
        "        if key in row['Test_Name']:\n",
        "            repeat_count = condition['repeat_count']\n",
        "            task_names = condition['task_names']\n",
        "            task_ids = condition['task_ids']\n",
        "            break  # Exit loop once the condition is matched\n",
        "\n",
        "    # Append each row with its corresponding Task_Name and Task_ID\n",
        "    for i in range(repeat_count):\n",
        "        new_row = row.copy()\n",
        "        new_row['Task_Name'] = task_names[i]\n",
        "        new_row['Task_ID'] = task_ids[i]\n",
        "        repeated_rows.append(new_row)\n",
        "\n",
        "# Create the new DataFrame df7 with repeated rows, Task_Name, and Task_ID\n",
        "df7 = pd.DataFrame(repeated_rows)\n",
        "\n",
        "# Step 6: Reset the index to maintain a clean DataFrame\n",
        "df7 = df7.reset_index(drop=True)\n",
        "\n",
        "# Define the Max_Score mapping for each Task_Name\n",
        "max_score_mapping = {\n",
        "    \"Scientific_Presentation_Style1\": 10,\n",
        "    \"Scientific_Presentation_Style2\": 8,\n",
        "    \"Typical_Question1\": 1,\n",
        "    \"Typical_Question2\": 1,\n",
        "    \"Typical_Question3\": 1,\n",
        "    \"Typical_Question4\": 1,\n",
        "    \"Direct_Quotation1\": 1,\n",
        "    \"Direct_Quotation2\": 1,\n",
        "    \"Indirect_Quotation\": 1,\n",
        "    \"Libraries_Publishers\": 5,\n",
        "    \"Literature_Quality1\": 1,\n",
        "    \"Literature_Quality2\": 1,\n",
        "    \"Literature_Quality3\": 1,\n",
        "    \"Literature_Quality4\": 1,\n",
        "    \"Overall_Quality_trustworthiness\": 3\n",
        "}\n",
        "\n",
        "# Apply the Max_Score mapping to the dataframe\n",
        "df7['Max_Score'] = df7['Task_Name'].map(max_score_mapping)\n",
        "\n",
        "# Function to generate random points\n",
        "def generate_points(max_score):\n",
        "    if max_score == 1:\n",
        "        return np.random.choice([0, 0.5, 1])\n",
        "    else:\n",
        "        return np.random.randint(1, max_score + 1)\n",
        "\n",
        "# Apply function to create 'Points_Reached' column\n",
        "df7['Points_Reached'] = df7['Max_Score'].apply(generate_points)\n",
        "\n",
        "# Create 'Serial' column with sequential numbers from 1 to number of rows\n",
        "df7['Serial'] = range(1, len(df7) + 1)\n",
        "\n",
        "# Reorder columns\n",
        "df7 = df7[['Serial', 'Student_ID', 'Test_ID', 'Test_Name', 'Test_Type', 'Task_Name', 'Task_ID', 'Points_Reached', 'Max_Score']]\n",
        "\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df7.head(50))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gqfEnLmUSqS",
        "outputId": "1e614d9a-dddb-4650-adbe-9f191c24215f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Serial  Student_ID  Test_ID               Test_Name Test_Type  \\\n",
            "0        1         445        1          ARS_Search_Gr2       ARS   \n",
            "1        2         445        1          ARS_Search_Gr2       ARS   \n",
            "2        3         445        1          ARS_Search_Gr2       ARS   \n",
            "3        4         445        1          ARS_Search_Gr2       ARS   \n",
            "4        5         445        1          ARS_Search_Gr2       ARS   \n",
            "5        6         445        1          ARS_Search_Gr2       ARS   \n",
            "6        7         445        2    Self_Test_Discussion        ST   \n",
            "7        8         445        2    Self_Test_Discussion        ST   \n",
            "8        9         445        2    Self_Test_Discussion        ST   \n",
            "9       10         445        2    Self_Test_Discussion        ST   \n",
            "10      11         445        3      ARS_Discussion_Gr2       ARS   \n",
            "11      12         445        3      ARS_Discussion_Gr2       ARS   \n",
            "12      13         445        3      ARS_Discussion_Gr2       ARS   \n",
            "13      14         445        3      ARS_Discussion_Gr2       ARS   \n",
            "14      15         445        5        Self_Test_Report        ST   \n",
            "15      16         445        5        Self_Test_Report        ST   \n",
            "16      17         445        5        Self_Test_Report        ST   \n",
            "17      18         445        6  Self_Test_Presentation        ST   \n",
            "18      19         445        6  Self_Test_Presentation        ST   \n",
            "19      20         445        7          ARS_Report_Gr2       ARS   \n",
            "20      21         445        7          ARS_Report_Gr2       ARS   \n",
            "21      22         445        7          ARS_Report_Gr2       ARS   \n",
            "22      23         445        8        Self_Test_Search        ST   \n",
            "23      24         445        8        Self_Test_Search        ST   \n",
            "24      25         445        8        Self_Test_Search        ST   \n",
            "25      26         445        8        Self_Test_Search        ST   \n",
            "26      27         445        8        Self_Test_Search        ST   \n",
            "27      28         445        8        Self_Test_Search        ST   \n",
            "28      29         445        9    ARS_Presentation_Gr2       ARS   \n",
            "29      30         445        9    ARS_Presentation_Gr2       ARS   \n",
            "30      31         474       10          ARS_Report_Gr2       ARS   \n",
            "31      32         474       10          ARS_Report_Gr2       ARS   \n",
            "32      33         474       10          ARS_Report_Gr2       ARS   \n",
            "33      34         474       12        Self_Test_Search        ST   \n",
            "34      35         474       12        Self_Test_Search        ST   \n",
            "35      36         474       12        Self_Test_Search        ST   \n",
            "36      37         474       12        Self_Test_Search        ST   \n",
            "37      38         474       12        Self_Test_Search        ST   \n",
            "38      39         474       12        Self_Test_Search        ST   \n",
            "39      40         474       13    ARS_Presentation_Gr2       ARS   \n",
            "40      41         474       13    ARS_Presentation_Gr2       ARS   \n",
            "41      42         474       14        Self_Test_Report        ST   \n",
            "42      43         474       14        Self_Test_Report        ST   \n",
            "43      44         474       14        Self_Test_Report        ST   \n",
            "44      45         474       15  Self_Test_Presentation        ST   \n",
            "45      46         474       15  Self_Test_Presentation        ST   \n",
            "46      47         474       16          ARS_Search_Gr2       ARS   \n",
            "47      48         474       16          ARS_Search_Gr2       ARS   \n",
            "48      49         474       16          ARS_Search_Gr2       ARS   \n",
            "49      50         474       16          ARS_Search_Gr2       ARS   \n",
            "\n",
            "                          Task_Name                                 Task_ID  \\\n",
            "0              Libraries_Publishers  idb4b827c3-7fa4-4e7c-b8a4-b8697682c5e2   \n",
            "1               Literature_Quality1  idf8870479-86b7-423f-b26d-7b0ce10953a0   \n",
            "2               Literature_Quality2  id4d2a3973-cd09-4438-9e5e-9cf7018d4856   \n",
            "3               Literature_Quality3  idc4302902-36ef-43c1-8461-7fe7003aeae6   \n",
            "4               Literature_Quality4  id88dd75cf-1ec0-4d53-bf36-891d0a4ffef8   \n",
            "5   Overall_Quality_trustworthiness  idcac92222-7b93-4ddd-ba3f-ad1e102f22a6   \n",
            "6                 Typical_Question1  id072938f8-9d4c-464a-a096-7779cde74fe6   \n",
            "7                 Typical_Question2  id6c761817-f2fe-47bd-8499-540aeed1cbcf   \n",
            "8                 Typical_Question3  id615426a1-9c8d-487a-9a49-d8636a489b31   \n",
            "9                 Typical_Question4  id4ee22677-08a9-4e7d-94d1-a9bf1fed9aaa   \n",
            "10                Typical_Question1  id072938f8-9d4c-464a-a096-7779cde74fe6   \n",
            "11                Typical_Question2  id6c761817-f2fe-47bd-8499-540aeed1cbcf   \n",
            "12                Typical_Question3  id615426a1-9c8d-487a-9a49-d8636a489b31   \n",
            "13                Typical_Question4  id4ee22677-08a9-4e7d-94d1-a9bf1fed9aaa   \n",
            "14                Direct_Quotation1  ide6f51f20-0250-4df5-917b-911cb8a628bf   \n",
            "15                Direct_Quotation2  id26fe11e5-5525-456d-9e9b-0810e68126df   \n",
            "16               Indirect_Quotation  idbe59c174-1a15-4682-b335-abff89b5c6db   \n",
            "17   Scientific_Presentation_Style1  idaf224ec3-be2d-45bb-9f3c-acc818407763   \n",
            "18   Scientific_Presentation_Style2  idfce2e221-452f-4828-bd05-266c2d27e3c0   \n",
            "19                Direct_Quotation1  ide6f51f20-0250-4df5-917b-911cb8a628bf   \n",
            "20                Direct_Quotation2  id26fe11e5-5525-456d-9e9b-0810e68126df   \n",
            "21               Indirect_Quotation  idbe59c174-1a15-4682-b335-abff89b5c6db   \n",
            "22             Libraries_Publishers  idb4b827c3-7fa4-4e7c-b8a4-b8697682c5e2   \n",
            "23              Literature_Quality1  idf8870479-86b7-423f-b26d-7b0ce10953a0   \n",
            "24              Literature_Quality2  id4d2a3973-cd09-4438-9e5e-9cf7018d4856   \n",
            "25              Literature_Quality3  idc4302902-36ef-43c1-8461-7fe7003aeae6   \n",
            "26              Literature_Quality4  id88dd75cf-1ec0-4d53-bf36-891d0a4ffef8   \n",
            "27  Overall_Quality_trustworthiness  idcac92222-7b93-4ddd-ba3f-ad1e102f22a6   \n",
            "28   Scientific_Presentation_Style1  idaf224ec3-be2d-45bb-9f3c-acc818407763   \n",
            "29   Scientific_Presentation_Style2  idfce2e221-452f-4828-bd05-266c2d27e3c0   \n",
            "30                Direct_Quotation1  ide6f51f20-0250-4df5-917b-911cb8a628bf   \n",
            "31                Direct_Quotation2  id26fe11e5-5525-456d-9e9b-0810e68126df   \n",
            "32               Indirect_Quotation  idbe59c174-1a15-4682-b335-abff89b5c6db   \n",
            "33             Libraries_Publishers  idb4b827c3-7fa4-4e7c-b8a4-b8697682c5e2   \n",
            "34              Literature_Quality1  idf8870479-86b7-423f-b26d-7b0ce10953a0   \n",
            "35              Literature_Quality2  id4d2a3973-cd09-4438-9e5e-9cf7018d4856   \n",
            "36              Literature_Quality3  idc4302902-36ef-43c1-8461-7fe7003aeae6   \n",
            "37              Literature_Quality4  id88dd75cf-1ec0-4d53-bf36-891d0a4ffef8   \n",
            "38  Overall_Quality_trustworthiness  idcac92222-7b93-4ddd-ba3f-ad1e102f22a6   \n",
            "39   Scientific_Presentation_Style1  idaf224ec3-be2d-45bb-9f3c-acc818407763   \n",
            "40   Scientific_Presentation_Style2  idfce2e221-452f-4828-bd05-266c2d27e3c0   \n",
            "41                Direct_Quotation1  ide6f51f20-0250-4df5-917b-911cb8a628bf   \n",
            "42                Direct_Quotation2  id26fe11e5-5525-456d-9e9b-0810e68126df   \n",
            "43               Indirect_Quotation  idbe59c174-1a15-4682-b335-abff89b5c6db   \n",
            "44   Scientific_Presentation_Style1  idaf224ec3-be2d-45bb-9f3c-acc818407763   \n",
            "45   Scientific_Presentation_Style2  idfce2e221-452f-4828-bd05-266c2d27e3c0   \n",
            "46             Libraries_Publishers  idb4b827c3-7fa4-4e7c-b8a4-b8697682c5e2   \n",
            "47              Literature_Quality1  idf8870479-86b7-423f-b26d-7b0ce10953a0   \n",
            "48              Literature_Quality2  id4d2a3973-cd09-4438-9e5e-9cf7018d4856   \n",
            "49              Literature_Quality3  idc4302902-36ef-43c1-8461-7fe7003aeae6   \n",
            "\n",
            "    Points_Reached  Max_Score  \n",
            "0              5.0          5  \n",
            "1              0.0          1  \n",
            "2              1.0          1  \n",
            "3              0.0          1  \n",
            "4              0.0          1  \n",
            "5              1.0          3  \n",
            "6              0.5          1  \n",
            "7              0.0          1  \n",
            "8              0.0          1  \n",
            "9              0.5          1  \n",
            "10             1.0          1  \n",
            "11             0.5          1  \n",
            "12             0.5          1  \n",
            "13             1.0          1  \n",
            "14             1.0          1  \n",
            "15             0.5          1  \n",
            "16             0.0          1  \n",
            "17             3.0         10  \n",
            "18             8.0          8  \n",
            "19             0.0          1  \n",
            "20             1.0          1  \n",
            "21             0.0          1  \n",
            "22             2.0          5  \n",
            "23             0.5          1  \n",
            "24             0.5          1  \n",
            "25             1.0          1  \n",
            "26             0.5          1  \n",
            "27             1.0          3  \n",
            "28             2.0         10  \n",
            "29             2.0          8  \n",
            "30             0.5          1  \n",
            "31             0.5          1  \n",
            "32             1.0          1  \n",
            "33             4.0          5  \n",
            "34             1.0          1  \n",
            "35             1.0          1  \n",
            "36             0.0          1  \n",
            "37             0.0          1  \n",
            "38             2.0          3  \n",
            "39             1.0         10  \n",
            "40             5.0          8  \n",
            "41             0.0          1  \n",
            "42             0.0          1  \n",
            "43             1.0          1  \n",
            "44             3.0         10  \n",
            "45             1.0          8  \n",
            "46             1.0          5  \n",
            "47             1.0          1  \n",
            "48             0.5          1  \n",
            "49             1.0          1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with pd.ExcelWriter('output_data.xlsx') as writer:\n",
        "    # Write each DataFrame to a separate sheet\n",
        "    df.to_excel(writer, sheet_name='Student', index=False)\n",
        "    df2.to_excel(writer, sheet_name='Student_Topic', index=False)\n",
        "    topic.to_excel(writer, sheet_name='Topic', index=False)\n",
        "    semester.to_excel(writer, sheet_name='Semester', index=False)\n",
        "    df5.to_excel(writer, sheet_name= 'Student_Test_Data', index=False)\n",
        "    df6.to_excel(writer, sheet_name= 'Recommendation_System_Data', index=False)\n",
        "    df7.to_excel(writer, sheet_name= 'Formative_Assessment_Data', index=False)"
      ],
      "metadata": {
        "id": "9ECnJgHhV-H_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}